{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5668bce7-d162-4a14-bfac-481bb0b3e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home Credit Default Risk - Traditional ML + Fairness-First Approach\n",
    "# Based on 1st place solution with fairness considerations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01236b7c-e8dc-4cc8-87db-f9eb99e29d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Libraries\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b042aa63-1ae9-48e5-a0dc-5f120029bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3e82105-9c39-498f-b67c-8675c7f0ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability & Fairness\n",
    "import shap\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.reductions import DemographicParity, ExponentiatedGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdca6300-71c8-4156-acde-e1470457f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0f8c40-5df8-4b3d-adbe-e9db0b2393c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98165a09-5408-4df3-a685-f3e69104d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d39747d-2ad3-4686-941e-cf0059ab0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_test.csv\t\t    home-credit-default-risk.zip\n",
      "application_train.csv\t\t    installments_payments.csv\n",
      "bureau_balance.csv\t\t    POS_CASH_balance.csv\n",
      "bureau.csv\t\t\t    previous_application.csv\n",
      "credit_card_balance.csv\t\t    sample_submission.csv\n",
      "HomeCredit_columns_description.csv  xloan.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db82475a-01f4-49a1-aa27-dd773aecf128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading Home Credit dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOME CREDIT RISK ASSESSMENT DEMO ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded training data: (307511, 122)\n",
      "INFO:__main__:Target distribution: {0: 282686, 1: 24825}\n",
      "INFO:__main__:Starting feature engineering...\n",
      "INFO:__main__:Feature engineering completed. Shape: (307511, 137)\n",
      "INFO:__main__:Preparing features for modeling...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert [['Cash loans' 'Cash loans' 'Revolving loans' ... 'Cash loans'\n  'Cash loans' 'Cash loans']] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 404\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# Run demo\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Model Performance Summary ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Traditional ML ensemble trained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 364\u001b[0m, in \u001b[0;36mrun_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    361\u001b[0m df_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_engineering()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Prepare for modeling\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Feature selection\u001b[39;00m\n\u001b[1;32m    367\u001b[0m X_selected, selected_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_selection(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 149\u001b[0m, in \u001b[0;36mHomeCreditRiskAssessment.prepare_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude_cols]\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Handle missing values\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m df[feature_cols] \u001b[38;5;241m=\u001b[39m df[feature_cols]\u001b[38;5;241m.\u001b[39mfillna(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m df[feature_cols]\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/frame.py:11706\u001b[0m, in \u001b[0;36mDataFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11698\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m  11699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m  11700\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11704\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11705\u001b[0m ):\n\u001b[0;32m> 11706\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11708\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/generic.py:12431\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(\n\u001b[1;32m  12425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12426\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12432\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmedian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/internals/managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/internals/blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[1;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/xloan/lib/python3.10/site-packages/pandas/core/nanops.py:787\u001b[0m, in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    785\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values)\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert [['Cash loans' 'Cash loans' 'Revolving loans' ... 'Cash loans'\n  'Cash loans' 'Cash loans']] to numeric"
     ]
    }
   ],
   "source": [
    "class HomeCreditRiskAssessment:\n",
    "    \"\"\"\n",
    "    Home Credit Risk Assessment với Traditional ML + Fairness-First approach\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        self.fairness_metrics = {}\n",
    "        self.explainer = None\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_selector = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load và basic preprocessing của Home Credit dataset\"\"\"\n",
    "        logger.info(\"Loading Home Credit dataset...\")\n",
    "        \n",
    "        # Load main tables\n",
    "        try:\n",
    "            self.app_train = pd.read_csv('application_train.csv')\n",
    "            self.app_test = pd.read_csv('application_test.csv')\n",
    "            self.bureau = pd.read_csv('bureau.csv')\n",
    "            self.bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "            self.prev_app = pd.read_csv('previous_application.csv')\n",
    "            self.pos_cash = pd.read_csv('POS_CASH_balance.csv')\n",
    "            self.installments = pd.read_csv('installments_payments.csv')\n",
    "            self.credit_card = pd.read_csv('credit_card_balance.csv')\n",
    "            \n",
    "            logger.info(f\"Loaded training data: {self.app_train.shape}\")\n",
    "            logger.info(f\"Target distribution: {self.app_train['TARGET'].value_counts().to_dict()}\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"File not found: {e}\")\n",
    "            # Create dummy data for demo\n",
    "            self._create_dummy_data()\n",
    "    \n",
    "    def _create_dummy_data(self):\n",
    "        \"\"\"Tạo dummy data cho demo khi không có file gốc\"\"\"\n",
    "        logger.info(\"Creating dummy data for demo...\")\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        n_samples = 10000\n",
    "        \n",
    "        # Main application data\n",
    "        self.app_train = pd.DataFrame({\n",
    "            'SK_ID_CURR': range(n_samples),\n",
    "            'TARGET': np.random.choice([0, 1], n_samples, p=[0.92, 0.08]),\n",
    "            'AMT_INCOME_TOTAL': np.random.lognormal(12, 0.5, n_samples),\n",
    "            'AMT_CREDIT': np.random.lognormal(13, 0.6, n_samples),\n",
    "            'AMT_ANNUITY': np.random.lognormal(10, 0.4, n_samples),\n",
    "            'AMT_GOODS_PRICE': np.random.lognormal(12.5, 0.7, n_samples),\n",
    "            'DAYS_BIRTH': np.random.randint(-25000, -6000, n_samples),\n",
    "            'DAYS_EMPLOYED': np.random.randint(-15000, 0, n_samples),\n",
    "            'CODE_GENDER': np.random.choice(['M', 'F'], n_samples, p=[0.35, 0.65]),\n",
    "            'NAME_EDUCATION_TYPE': np.random.choice([\n",
    "                'Secondary / secondary special', 'Higher education', \n",
    "                'Incomplete higher', 'Lower secondary'\n",
    "            ], n_samples, p=[0.7, 0.2, 0.08, 0.02]),\n",
    "            'NAME_FAMILY_STATUS': np.random.choice([\n",
    "                'Married', 'Single / not married', 'Civil marriage', 'Separated', 'Widow'\n",
    "            ], n_samples, p=[0.6, 0.2, 0.1, 0.05, 0.05]),\n",
    "            'CNT_CHILDREN': np.random.poisson(0.4, n_samples),\n",
    "            'EXT_SOURCE_1': np.random.beta(2, 3, n_samples),\n",
    "            'EXT_SOURCE_2': np.random.beta(2, 3, n_samples),\n",
    "            'EXT_SOURCE_3': np.random.beta(2, 3, n_samples),\n",
    "            'REGION_POPULATION_RELATIVE': np.random.uniform(0.0001, 0.1, n_samples)\n",
    "        })\n",
    "        \n",
    "        # Test data\n",
    "        self.app_test = self.app_train.copy()\n",
    "        self.app_test = self.app_test.drop('TARGET', axis=1)\n",
    "        self.app_test['SK_ID_CURR'] = range(n_samples, n_samples*2)\n",
    "        \n",
    "        logger.info(\"Dummy data created successfully\")\n",
    "    \n",
    "    def feature_engineering(self):\n",
    "        \"\"\"Feature engineering dựa trên winning solution\"\"\"\n",
    "        logger.info(\"Starting feature engineering...\")\n",
    "        \n",
    "        df = self.app_train.copy()\n",
    "        \n",
    "        # 1. Basic derived features\n",
    "        df['CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "        df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "        df['CREDIT_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "        df['GOODS_PRICE_CREDIT_RATIO'] = df['AMT_GOODS_PRICE'] / df['AMT_CREDIT']\n",
    "        \n",
    "        # 2. Age and employment features\n",
    "        df['AGE_YEARS'] = (-df['DAYS_BIRTH'] / 365).astype(int)\n",
    "        df['EMPLOYED_YEARS'] = (-df['DAYS_EMPLOYED'] / 365).astype(int)\n",
    "        df['EMPLOYED_YEARS'] = df['EMPLOYED_YEARS'].apply(lambda x: max(0, x))\n",
    "        \n",
    "        # Age groups for fairness analysis\n",
    "        df['AGE_GROUP'] = pd.cut(df['AGE_YEARS'], \n",
    "                                bins=[0, 25, 35, 45, 55, 100], \n",
    "                                labels=['18-25', '26-35', '36-45', '46-55', '55+'])\n",
    "        \n",
    "        # 3. Income brackets\n",
    "        df['INCOME_BRACKET'] = pd.qcut(df['AMT_INCOME_TOTAL'], \n",
    "                                      q=5, \n",
    "                                      labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "        \n",
    "        # 4. External source combinations (từ winning solution)\n",
    "        df['EXT_SOURCE_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "        df['EXT_SOURCE_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "        df['EXT_SOURCE_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "        \n",
    "        # 5. Binary indicators\n",
    "        df['HAS_CAR'] = (df.get('FLAG_OWN_CAR', 'N') == 'Y').astype(int)\n",
    "        df['HAS_REALTY'] = (df.get('FLAG_OWN_REALTY', 'N') == 'Y').astype(int)\n",
    "        df['HAS_CHILDREN'] = (df['CNT_CHILDREN'] > 0).astype(int)\n",
    "        \n",
    "        # 6. Risk categories (business logic)\n",
    "        df['HIGH_CREDIT_RISK'] = (\n",
    "            (df['CREDIT_INCOME_RATIO'] > 10) | \n",
    "            (df['ANNUITY_INCOME_RATIO'] > 0.5)\n",
    "        ).astype(int)\n",
    "        \n",
    "        self.df_engineered = df\n",
    "        logger.info(f\"Feature engineering completed. Shape: {df.shape}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_features(self):\n",
    "        \"\"\"Chuẩn bị features cho modeling\"\"\"\n",
    "        logger.info(\"Preparing features for modeling...\")\n",
    "        \n",
    "        df = self.df_engineered.copy()\n",
    "        \n",
    "        # Categorical features cần encode\n",
    "        categorical_features = [\n",
    "            'CODE_GENDER', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "            'AGE_GROUP', 'INCOME_BRACKET'\n",
    "        ]\n",
    "        \n",
    "        # Label encoding\n",
    "        for col in categorical_features:\n",
    "            if col in df.columns:\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col].astype(str))\n",
    "                self.label_encoders[col] = le\n",
    "        \n",
    "        # Features for modeling (loại bỏ ID và target)\n",
    "        exclude_cols = ['SK_ID_CURR', 'TARGET']\n",
    "        feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "        \n",
    "        # Handle missing values\n",
    "        df[feature_cols] = df[feature_cols].fillna(df[feature_cols].median())\n",
    "        \n",
    "        self.X = df[feature_cols]\n",
    "        self.y = df['TARGET']\n",
    "        self.feature_names = feature_cols\n",
    "        \n",
    "        # Protected attributes cho fairness\n",
    "        self.protected_attrs = {\n",
    "            'gender': df['CODE_GENDER'],\n",
    "            'age_group': df['AGE_GROUP'],\n",
    "            'education': df['NAME_EDUCATION_TYPE']\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Features prepared. Shape: {self.X.shape}\")\n",
    "        return self.X, self.y\n",
    "    \n",
    "    def feature_selection(self, k=100):\n",
    "        \"\"\"Feature selection using statistical tests\"\"\"\n",
    "        logger.info(f\"Selecting top {k} features...\")\n",
    "        \n",
    "        self.feature_selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        X_selected = self.feature_selector.fit_transform(self.X, self.y)\n",
    "        \n",
    "        # Get selected feature names\n",
    "        selected_mask = self.feature_selector.get_support()\n",
    "        self.selected_features = [self.feature_names[i] for i, selected in enumerate(selected_mask) if selected]\n",
    "        \n",
    "        logger.info(f\"Selected {len(self.selected_features)} features\")\n",
    "        return X_selected, self.selected_features\n",
    "    \n",
    "    def train_models(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \"\"\"Train ensemble của LightGBM, XGBoost, và Logistic Regression\"\"\"\n",
    "        logger.info(\"Training models...\")\n",
    "        \n",
    "        # 1. LightGBM\n",
    "        lgb_params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        self.models['lgb'] = lgb.LGBMClassifier(**lgb_params, n_estimators=1000)\n",
    "        self.models['lgb'].fit(X_train, y_train, \n",
    "                              eval_set=[(X_val, y_val)] if X_val is not None else None,\n",
    "                              early_stopping_rounds=100 if X_val is not None else None,\n",
    "                              verbose=False)\n",
    "        \n",
    "        # 2. XGBoost\n",
    "        xgb_params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        self.models['xgb'] = xgb.XGBClassifier(**xgb_params, n_estimators=1000)\n",
    "        self.models['xgb'].fit(X_train, y_train,\n",
    "                              eval_set=[(X_val, y_val)] if X_val is not None else None,\n",
    "                              early_stopping_rounds=100 if X_val is not None else None,\n",
    "                              verbose=False)\n",
    "        \n",
    "        # 3. Logistic Regression (for interpretability)\n",
    "        self.models['lr'] = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        self.models['lr'].fit(X_train_scaled, y_train)\n",
    "        \n",
    "        logger.info(\"Models trained successfully\")\n",
    "    \n",
    "    def predict_ensemble(self, X):\n",
    "        \"\"\"Ensemble prediction với trọng số tối ưu\"\"\"\n",
    "        predictions = {}\n",
    "        \n",
    "        # LightGBM prediction\n",
    "        predictions['lgb'] = self.models['lgb'].predict_proba(X)[:, 1]\n",
    "        \n",
    "        # XGBoost prediction  \n",
    "        predictions['xgb'] = self.models['xgb'].predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Logistic Regression prediction\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        predictions['lr'] = self.models['lr'].predict_proba(X_scaled)[:, 1]\n",
    "        \n",
    "        # Ensemble với trọng số từ winning solution\n",
    "        ensemble_pred = (0.6 * predictions['lgb'] + \n",
    "                        0.3 * predictions['xgb'] + \n",
    "                        0.1 * predictions['lr'])\n",
    "        \n",
    "        return ensemble_pred, predictions\n",
    "    \n",
    "    def evaluate_fairness(self, y_true, y_pred, protected_attr):\n",
    "        \"\"\"Đánh giá fairness metrics\"\"\"\n",
    "        logger.info(\"Evaluating fairness metrics...\")\n",
    "        \n",
    "        fairness_metrics = {}\n",
    "        \n",
    "        for attr_name, attr_values in protected_attr.items():\n",
    "            # Demographics parity difference\n",
    "            dp_diff = demographic_parity_difference(\n",
    "                y_true, y_pred > 0.5, sensitive_features=attr_values\n",
    "            )\n",
    "            \n",
    "            # Equalized odds difference\n",
    "            eo_diff = equalized_odds_difference(\n",
    "                y_true, y_pred > 0.5, sensitive_features=attr_values\n",
    "            )\n",
    "            \n",
    "            fairness_metrics[attr_name] = {\n",
    "                'demographic_parity_diff': dp_diff,\n",
    "                'equalized_odds_diff': eo_diff\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"{attr_name} - DP diff: {dp_diff:.4f}, EO diff: {eo_diff:.4f}\")\n",
    "        \n",
    "        self.fairness_metrics = fairness_metrics\n",
    "        return fairness_metrics\n",
    "    \n",
    "    def setup_explainability(self, X_sample):\n",
    "        \"\"\"Setup SHAP explainer\"\"\"\n",
    "        logger.info(\"Setting up SHAP explainer...\")\n",
    "        \n",
    "        # Use LightGBM for SHAP (fastest for tree models)\n",
    "        self.explainer = shap.TreeExplainer(self.models['lgb'])\n",
    "        self.shap_values = self.explainer.shap_values(X_sample)\n",
    "        \n",
    "        logger.info(\"SHAP explainer ready\")\n",
    "    \n",
    "    def explain_prediction(self, customer_data, customer_id=0):\n",
    "        \"\"\"Giải thích prediction cho một customer cụ thể\"\"\"\n",
    "        if self.explainer is None:\n",
    "            logger.error(\"SHAP explainer not initialized\")\n",
    "            return None\n",
    "        \n",
    "        # Get SHAP values for this customer\n",
    "        shap_vals = self.explainer.shap_values(customer_data.reshape(1, -1))\n",
    "        \n",
    "        # Create explanation\n",
    "        explanation = {\n",
    "            'expected_value': self.explainer.expected_value,\n",
    "            'shap_values': shap_vals[0],\n",
    "            'feature_names': self.selected_features,\n",
    "            'customer_data': customer_data\n",
    "        }\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def create_dashboard_data(self, X_test, predictions):\n",
    "        \"\"\"Tạo data cho dashboard\"\"\"\n",
    "        dashboard_data = {\n",
    "            'predictions': predictions,\n",
    "            'feature_importance': dict(zip(\n",
    "                self.selected_features,\n",
    "                self.models['lgb'].feature_importances_\n",
    "            )),\n",
    "            'fairness_metrics': self.fairness_metrics,\n",
    "            'model_performance': {\n",
    "                'auc_lgb': 0.795,  # Placeholder\n",
    "                'auc_xgb': 0.790,\n",
    "                'auc_ensemble': 0.803\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return dashboard_data\n",
    "    \n",
    "    def save_model(self, filepath='home_credit_model.pkl'):\n",
    "        \"\"\"Lưu model và components\"\"\"\n",
    "        model_package = {\n",
    "            'models': self.models,\n",
    "            'scaler': self.scaler,\n",
    "            'label_encoders': self.label_encoders,\n",
    "            'feature_selector': self.feature_selector,\n",
    "            'selected_features': self.selected_features,\n",
    "            'explainer': self.explainer\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_package, filepath)\n",
    "        logger.info(f\"Model saved to {filepath}\")\n",
    "    \n",
    "    def load_model(self, filepath='home_credit_model.pkl'):\n",
    "        \"\"\"Load model và components\"\"\"\n",
    "        model_package = joblib.load(filepath)\n",
    "        \n",
    "        self.models = model_package['models']\n",
    "        self.scaler = model_package['scaler']\n",
    "        self.label_encoders = model_package['label_encoders']\n",
    "        self.feature_selector = model_package['feature_selector']\n",
    "        self.selected_features = model_package['selected_features']\n",
    "        self.explainer = model_package['explainer']\n",
    "        \n",
    "        logger.info(f\"Model loaded from {filepath}\")\n",
    "\n",
    "# Demo Usage\n",
    "def run_demo():\n",
    "    \"\"\"Chạy demo hoàn chỉnh\"\"\"\n",
    "    print(\"=== HOME CREDIT RISK ASSESSMENT DEMO ===\")\n",
    "    \n",
    "    # Initialize\n",
    "    model = HomeCreditRiskAssessment()\n",
    "    \n",
    "    # Load data\n",
    "    model.load_data()\n",
    "    \n",
    "    # Feature engineering\n",
    "    df_features = model.feature_engineering()\n",
    "    \n",
    "    # Prepare for modeling\n",
    "    X, y = model.prepare_features()\n",
    "    \n",
    "    # Feature selection\n",
    "    X_selected, selected_features = model.feature_selection(k=50)\n",
    "    \n",
    "    # Train-validation split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_selected, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train models\n",
    "    model.train_models(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Predictions\n",
    "    ensemble_pred, individual_preds = model.predict_ensemble(X_val)\n",
    "    \n",
    "    # Evaluate\n",
    "    auc_score = roc_auc_score(y_val, ensemble_pred)\n",
    "    print(f\"Validation AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    # Fairness evaluation\n",
    "    protected_attrs_val = {k: v.iloc[X_val.index] for k, v in model.protected_attrs.items()}\n",
    "    fairness_metrics = model.evaluate_fairness(y_val, ensemble_pred, protected_attrs_val)\n",
    "    \n",
    "    # Setup explainability\n",
    "    model.setup_explainability(X_val[:100])\n",
    "    \n",
    "    # Example explanation\n",
    "    explanation = model.explain_prediction(X_val.iloc[0].values)\n",
    "    print(f\"Example explanation ready for customer 0\")\n",
    "    \n",
    "    # Save model\n",
    "    model.save_model('home_credit_demo_model.pkl')\n",
    "    \n",
    "    print(\"Demo completed successfully!\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run demo\n",
    "    trained_model = run_demo()\n",
    "    \n",
    "    print(\"\\n=== Model Performance Summary ===\")\n",
    "    print(\"✅ Traditional ML ensemble trained\")\n",
    "    print(\"✅ Fairness metrics calculated\") \n",
    "    print(\"✅ SHAP explanations ready\")\n",
    "    print(\"✅ Model saved for production\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
